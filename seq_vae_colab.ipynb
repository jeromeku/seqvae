{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKTCmMfZdJUW"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6097,
     "status": "ok",
     "timestamp": 1571320155767,
     "user": {
      "displayName": "Jerome Ku",
      "photoUrl": "",
      "userId": "15659096259355675214"
     },
     "user_tz": 420
    },
    "id": "rdOrvh8lZMD3",
    "outputId": "472d1d1b-2d14-4048-c95f-1f5cde1d4d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.2.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already up-to-date: tensorflow_probability in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow_probability) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow_probability) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle==1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_probability) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: gast<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow_probability) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_probability) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow-gpu\n",
    "!pip install -U tensorflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDS0Mn1TZdRW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 678,
     "status": "ok",
     "timestamp": 1571320163844,
     "user": {
      "displayName": "Jerome Ku",
      "photoUrl": "",
      "userId": "15659096259355675214"
     },
     "user_tz": 420
    },
    "id": "-oCnxLDtnPdn",
    "outputId": "19ce1ab7-f5a5-4f17-dfaf-43d480481e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 17 14:07:00 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1070    Off  | 00000000:02:00.0  On |                  N/A |\n",
      "|  0%   45C    P8    13W / 180W |   3470MiB /  8111MiB |      4%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 1080    Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "|  0%   39C    P8    10W / 240W |    117MiB /  8119MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1932      G   /usr/lib/xorg/Xorg                          2633MiB |\n",
      "|    0      4256      G   compiz                                       228MiB |\n",
      "|    0      5856      G   ...quest-channel-token=2060769103087579268   293MiB |\n",
      "|    0      7868      C   /home/jeromeku/miniconda3/bin/python          83MiB |\n",
      "|    0     11439      G   /usr/bin/vlc                                  95MiB |\n",
      "|    0     17855      G   ...uest-channel-token=16141749682434956010    31MiB |\n",
      "|    0     18617      G   /snap/vlc/1049/usr/bin/vlc                    53MiB |\n",
      "|    0     21441      G   ...quest-channel-token=1827438075631690996    43MiB |\n",
      "|    1      7868      C   /home/jeromeku/miniconda3/bin/python         105MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1571320168454,
     "user": {
      "displayName": "Jerome Ku",
      "photoUrl": "",
      "userId": "15659096259355675214"
     },
     "user_tz": 420
    },
    "id": "1Sz7lGmi2E5R",
    "outputId": "efbd5a9d-524f-413e-ed49-f3eb8bd6cd11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1247,
     "status": "ok",
     "timestamp": 1571320194283,
     "user": {
      "displayName": "Jerome Ku",
      "photoUrl": "",
      "userId": "15659096259355675214"
     },
     "user_tz": 420
    },
    "id": "t-NOL_yLA-AZ",
    "outputId": "6b031029-199d-43f6-cbe6-f3c5252075b1"
   },
   "outputs": [],
   "source": [
    "project_id = 'research-256112'\n",
    "bucket_name = 'gs://jeromeku-seqvae-colab'\n",
    "!gcloud config set project {project_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90zDawD9BN4Y"
   },
   "outputs": [],
   "source": [
    "def authenticate():\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Js4llURSBdlF"
   },
   "outputs": [],
   "source": [
    "authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9740,
     "status": "ok",
     "timestamp": 1571320218885,
     "user": {
      "displayName": "Jerome Ku",
      "photoUrl": "",
      "userId": "15659096259355675214"
     },
     "user_tz": 420
    },
    "id": "rjiTCBc_BmBw",
    "outputId": "e1bfb789-58d0-4ba2-82fe-2639dcd622c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://jeromeku-seqvae-colab/test.npz...\n",
      "Copying gs://jeromeku-seqvae-colab/train.npz...\n",
      "- [2/2 files][486.3 MiB/486.3 MiB] 100% Done   8.8 MiB/s ETA 00:00:00           \n",
      "Operation completed over 2 objects/486.3 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "def extract_array(npz):\n",
    "  return np.stack([t for t in npz.values()], axis=0) \n",
    "\n",
    "!gsutil -m cp {bucket_name}/*.npz  .\n",
    "train = extract_array(np.load('./train.npz'))\n",
    "test = extract_array(np.load('./test.npz'))\n",
    "\n",
    "train_ds, test_ds = map(tf.data.Dataset.from_tensor_slices, [train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1571320221452,
     "user": {
      "displayName": "Jerome Ku",
      "photoUrl": "",
      "userId": "15659096259355675214"
     },
     "user_tz": 420
    },
    "id": "3h-b8lhRG_I5",
    "outputId": "8a549a49-5a36-4139-b4ae-cb9bdba810ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcb34648710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq = np.concatenate([*train[0]], axis=1)\n",
    "plt.imshow(seq)\n",
    "\n",
    "#Alternatively\n",
    "def plot_sprites(x):\n",
    "  fig, axes = plt.subplots(1, len(x))\n",
    "\n",
    "  for i, ax in enumerate(axes):\n",
    "    _ = ax.imshow(x[i])\n",
    "    ax.axis('off')\n",
    "  \n",
    "  return fig, axes\n",
    "#fig, axes = plot_sprites(train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1571320222068,
     "user": {
      "displayName": "Jerome Ku",
      "photoUrl": "",
      "userId": "15659096259355675214"
     },
     "user_tz": 420
    },
    "id": "Uea9KV0sYe56",
    "outputId": "1c3616e9-7f08-43a0-f720-f22e19462b1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sprites(length=8, frame_size=64, channels=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sprites = namedtuple('Sprites', ['length', 'frame_size', 'channels'])\n",
    "sprites = Sprites(8, 64, 3)\n",
    "sprites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1571320224867,
     "user": {
      "displayName": "Jerome Ku",
      "photoUrl": "",
      "userId": "15659096259355675214"
     },
     "user_tz": 420
    },
    "id": "RWK3TdoJWT4f",
    "outputId": "2f7ae95b-37e1-47f4-ca13-be603a1c9506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'seqvae' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jeromeku/seqvae.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHlTJPtjdJUd"
   },
   "outputs": [],
   "source": [
    "SOURCE_PATH = './seqvae'\n",
    "if not SOURCE_PATH in sys.path:\n",
    "    sys.path.append(SOURCE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xtclTyEdekX"
   },
   "outputs": [],
   "source": [
    "#!cd seqvae/ && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u61KbbardJUh"
   },
   "outputs": [],
   "source": [
    "import disentangled.models as models\n",
    "\n",
    "from disentangled.flags import FLAGS\n",
    "FLAGS.mark_as_parsed()\n",
    "from disentangled.summary import visualize_reconstruction, visualize_qualitative_analysis, image_summary, summarize_dist_params, summarize_mean_in_nats_and_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HqqCxON3dJUn"
   },
   "outputs": [],
   "source": [
    "#Build model\n",
    "model = models.DisentangledSequentialVAE(\n",
    "      latent_size_static=FLAGS.latent_size_static,\n",
    "      latent_size_dynamic=FLAGS.latent_size_dynamic,\n",
    "      hidden_size=FLAGS.hidden_size, channels=sprites.channels,\n",
    "      latent_posterior=FLAGS.latent_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Na6uoJNvdJUq"
   },
   "outputs": [],
   "source": [
    "#Optimizer and learning rate schedule\n",
    "step = tf.Variable(0, dtype=tf.int64, trainable=False) \n",
    "schedule = tf.compat.v1.train.cosine_decay(FLAGS.learning_rate, step, FLAGS.max_steps)\n",
    "optimizer = tf.keras.optimizers.Adam(schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3472,
     "status": "ok",
     "timestamp": 1571322930716,
     "user": {
      "displayName": "Jerome Ku",
      "photoUrl": "",
      "userId": "15659096259355675214"
     },
     "user_tz": 420
    },
    "id": "v2ruokjndJUt",
    "outputId": "42c40d98-2d62-4f98-a2d2-3d7d32751d5e"
   },
   "outputs": [],
   "source": [
    "#GCS housekeeping\n",
    "CLEAN = False\n",
    "\n",
    "if CLEAN:\n",
    "  !gsutil rm -r {bucket_name}/logs {bucket_name}/tf_ckpts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wYRpTbXtGB-p"
   },
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error executing an HTTP request: HTTP response code 401 with body '{\n  \"error\": {\n    \"code\": 401,\n    \"message\": \"Anonymous caller does not have storage.objects.list access to jeromeku-seqvae-colab.\",\n    \"errors\": [\n      {\n        \"message\": \"Anonymous caller does not have storage.objects.list access to jeromeku-seqvae-colab.\",\n        \"domain\": \"global\",\n        \"reason\": \"required\",\n        \"locationType\": \"header\",\n        \"location\": \"Authorization\"\n      }\n    ]\n  }\n}\n'\n\t when reading gs://jeromeku-seqvae-colab/logs/191017_135952/train/ [Op:CreateSummaryFileWriter]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8bbdf6a82cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%y%m%d_%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfile_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_as_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mcreate_file_writer_v2\u001b[0;34m(logdir, max_queue, flush_millis, filename_suffix, name)\u001b[0m\n\u001b[1;32m    389\u001b[0m               filename_suffix=filename_suffix),\n\u001b[1;32m    390\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m           v2=True)\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shared_name, init_op_fn, name, v2)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# TODO(nickfelt): cache other constructed ops in graph mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_op_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_op_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_op_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_summary_ops.py\u001b[0m in \u001b[0;36mcreate_summary_file_writer\u001b[0;34m(writer, logdir, max_queue, flush_millis, filename_suffix, name)\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: Error executing an HTTP request: HTTP response code 401 with body '{\n  \"error\": {\n    \"code\": 401,\n    \"message\": \"Anonymous caller does not have storage.objects.list access to jeromeku-seqvae-colab.\",\n    \"errors\": [\n      {\n        \"message\": \"Anonymous caller does not have storage.objects.list access to jeromeku-seqvae-colab.\",\n        \"domain\": \"global\",\n        \"reason\": \"required\",\n        \"locationType\": \"header\",\n        \"location\": \"Authorization\"\n      }\n    ]\n  }\n}\n'\n\t when reading gs://jeromeku-seqvae-colab/logs/191017_135952/train/ [Op:CreateSummaryFileWriter]"
     ]
    }
   ],
   "source": [
    "#Tensorboard  \n",
    "timestamp = datetime.strftime(datetime.today(), \"%y%m%d_%H%M%S\")\n",
    "logdir = os.path.join(bucket_name, 'logs',)\n",
    "file_writer = tf.summary.create_file_writer(os.path.join(logdir, timestamp, 'train'))\n",
    "file_writer.set_as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHLJ9YeadJUw"
   },
   "outputs": [],
   "source": [
    "#Checkpointing\n",
    "checkpoint = tf.train.Checkpoint(step=step, optimizer=optimizer, net=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, os.path.join(bucket_name, 'tf_ckpts', timestamp), max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1888,
     "status": "ok",
     "timestamp": 1571323182150,
     "user": {
      "displayName": "Jerome Ku",
      "photoUrl": "",
      "userId": "15659096259355675214"
     },
     "user_tz": 420
    },
    "id": "kBs-PJXbDKlF",
    "outputId": "bd355d1e-509c-4745-c0cb-e3b529ea7fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://jeromeku-seqvae-colab/test.npz\n",
      "gs://jeromeku-seqvae-colab/train.npz\n",
      "\n",
      "gs://jeromeku-seqvae-colab/logs/:\n",
      "gs://jeromeku-seqvae-colab/logs/191017_143935/\n",
      "gs://jeromeku-seqvae-colab/logs/train_data/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {bucket_name}/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_cPVUGfc7JG"
   },
   "outputs": [],
   "source": [
    "def train_step(*, model, optimizer, train_ds, test_ds, FLAGS, writer, checkpoint, checkpoint_manager):\n",
    "    if checkpoint_manager.latest_checkpoint:\n",
    "        checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "        print(f\"Restored from {checkpoint_manager.latest_checkpoint}\")\n",
    "    else:\n",
    "        print(\"Initializing from scratch\")\n",
    "        \n",
    "    step = checkpoint.step\n",
    "    \n",
    "    for inputs in train_ds.prefetch(buffer_size=None):\n",
    "        with tf.compat.v2.summary.record_if(\n",
    "            lambda: tf.math.equal(0, step % FLAGS.log_steps)\n",
    "        ):\n",
    "            tf.compat.v2.summary.histogram(\"image\", data=inputs, step=step)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            features = model.compressor(inputs)  # (batch, timesteps, hidden)\n",
    "            static_sample, static_posterior = model.sample_static_posterior(\n",
    "                features, FLAGS.num_samples\n",
    "            )  # (samples, batch, latent)\n",
    "            dynamic_sample, dynamic_posterior = model.sample_dynamic_posterior(\n",
    "                features, FLAGS.num_samples, static_sample\n",
    "            )  # (sampl, N, T, latent)\n",
    "            likelihood = model.decoder((dynamic_sample, static_sample))\n",
    "\n",
    "            reconstruction = tf.reduce_mean(  # integrate samples\n",
    "                input_tensor=likelihood.mean()[: FLAGS.num_reconstruction_samples],\n",
    "                axis=0,\n",
    "            )\n",
    "            visualize_reconstruction(\n",
    "                inputs, reconstruction, step, name=\"train_reconstruction\"\n",
    "            )\n",
    "\n",
    "            static_prior = model.static_prior()\n",
    "            _, dynamic_prior = model.sample_dynamic_prior(\n",
    "                FLAGS.num_samples, FLAGS.batch_size, sprites.length\n",
    "            )\n",
    "\n",
    "            if FLAGS.enable_debug_logging:\n",
    "                summarize_dist_params(static_prior, \"static_prior\", step)\n",
    "                summarize_dist_params(static_posterior, \"static_posterior\", step)\n",
    "                summarize_dist_params(dynamic_prior, \"dynamic_prior\", step)\n",
    "                summarize_dist_params(dynamic_posterior, \"dynamic_posterior\", step)\n",
    "                summarize_dist_params(likelihood, \"likelihood\", step)\n",
    "\n",
    "            static_prior_log_prob = static_prior.log_prob(static_sample)\n",
    "            static_posterior_log_prob = static_posterior.log_prob(static_sample)\n",
    "            dynamic_prior_log_prob = tf.reduce_sum(\n",
    "                input_tensor=dynamic_prior.log_prob(dynamic_sample), axis=-1\n",
    "            )  # sum time\n",
    "            dynamic_posterior_log_prob = tf.reduce_sum(\n",
    "                input_tensor=dynamic_posterior.log_prob(dynamic_sample), axis=-1\n",
    "            )  # sum time\n",
    "            likelihood_log_prob = tf.reduce_sum(\n",
    "                input_tensor=likelihood.log_prob(inputs), axis=-1\n",
    "            )  # sum time\n",
    "\n",
    "            if FLAGS.enable_debug_logging:\n",
    "                with tf.compat.v1.name_scope(\"log_probs\"):\n",
    "                    summarize_mean_in_nats_and_bits(\n",
    "                        static_prior_log_prob, FLAGS.latent_size_static, \"static_prior\", step\n",
    "                    )\n",
    "                    summarize_mean_in_nats_and_bits(\n",
    "                        static_posterior_log_prob,\n",
    "                        FLAGS.latent_size_static,\n",
    "                        \"static_posterior\", step\n",
    "                    )\n",
    "                    summarize_mean_in_nats_and_bits(\n",
    "                        dynamic_prior_log_prob,\n",
    "                        FLAGS.latent_size_dynamic * sprites.length,\n",
    "                        \"dynamic_prior\", step\n",
    "                    )\n",
    "                    summarize_mean_in_nats_and_bits(\n",
    "                        dynamic_posterior_log_prob,\n",
    "                        FLAGS.latent_size_dynamic * sprites.length,\n",
    "                        \"dynamic_posterior\", step\n",
    "                    )\n",
    "                    summarize_mean_in_nats_and_bits(\n",
    "                        likelihood_log_prob,\n",
    "                        sprites.frame_size ** 2\n",
    "                        * sprites.channels\n",
    "                        * sprites.length,\n",
    "                        \"likelihood\", step\n",
    "                    )\n",
    "\n",
    "            elbo = tf.reduce_mean(\n",
    "                input_tensor=static_prior_log_prob\n",
    "                - static_posterior_log_prob\n",
    "                + dynamic_prior_log_prob\n",
    "                - dynamic_posterior_log_prob\n",
    "                + likelihood_log_prob\n",
    "            )\n",
    "            loss = -elbo\n",
    "            tf.compat.v2.summary.scalar(\"elbo\", elbo, step=step)\n",
    "\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        grads, global_norm = tf.clip_by_global_norm(grads, FLAGS.clip_norm)\n",
    "        grads_and_vars = list(zip(grads, model.variables))  # allow reuse in py3\n",
    "        if FLAGS.enable_debug_logging:\n",
    "            with tf.compat.v1.name_scope(\"grads\"):\n",
    "                tf.compat.v2.summary.scalar(\"global_norm_grads\", global_norm, step=step)\n",
    "                tf.compat.v2.summary.scalar(\n",
    "                    \"global_norm_grads_clipped\", tf.linalg.global_norm(grads), step=step\n",
    "                )\n",
    "            for grad, var in grads_and_vars:\n",
    "                with tf.compat.v1.name_scope(\"grads\"):\n",
    "                    tf.compat.v2.summary.histogram(\n",
    "                        \"{}/grad\".format(var.name), data=grad, step=step\n",
    "                    )\n",
    "                with tf.compat.v1.name_scope(\"vars\"):\n",
    "                    tf.compat.v2.summary.histogram(var.name, data=var, step=step)\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "\n",
    "        is_log_step = step.numpy() % FLAGS.log_steps == 0\n",
    "        is_final_step = step.numpy() == FLAGS.max_steps\n",
    "        if is_log_step or is_final_step:\n",
    "            checkpoint_manager.save()\n",
    "            print(\"ELBO ({}/{}): {}\".format(step.numpy(), FLAGS.max_steps, elbo.numpy()))\n",
    "            with tf.compat.v2.summary.record_if(True):\n",
    "                val_data = test_ds.take(20)\n",
    "                inputs = next(iter(val_data.shuffle(20).batch(3)))\n",
    "                visualize_qualitative_analysis(\n",
    "                    inputs, model, step, FLAGS.num_reconstruction_samples\n",
    "                )\n",
    "        step.assign_add(1)\n",
    "        writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ssKLS1-F3Uzl",
    "outputId": "0494825a-5309-4d40-eb58-b51bf784a631"
   },
   "outputs": [],
   "source": [
    "FLAGS.enable_debug_logging = True\n",
    "FLAGS.batch_size = 32 #default 32\n",
    "FLAGS.max_steps = 1000 #default 10000\n",
    "FLAGS.log_steps = 10\n",
    "train_ds = train_ds.shuffle(1000).repeat()\n",
    "train_set = train_ds.batch(FLAGS.batch_size).take(FLAGS.max_steps)\n",
    "test_set = test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ssKLS1-F3Uzl",
    "outputId": "0494825a-5309-4d40-eb58-b51bf784a631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO (0/1000): -93402.8984375\n"
     ]
    }
   ],
   "source": [
    "train_step(model=model, optimizer=optimizer, train_ds=train_set, test_ds=test_set, FLAGS=FLAGS, writer=file_writer, checkpoint_manager=ckpt_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BQMcRFJFmJv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of seq_vae_colab.ipynb",
   "provenance": [
    {
     "file_id": "1MK7xpsng1FwDS1Ry1qOu9mCD6ab7BRKF",
     "timestamp": 1571313719320
    },
    {
     "file_id": "https://github.com/jeromeku/seqvae/blob/master/seq_vae_colab.ipynb",
     "timestamp": 1571304778525
    }
   ]
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
